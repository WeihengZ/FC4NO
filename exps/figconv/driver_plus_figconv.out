
====================
== NVIDIA Modulus ==
====================

NVIDIA Release 24.09 (build 18526012)
Modulus PyPi Version 0.9.0 (Git Commit: eb01d2a)
Modulus Sym PyPi Version 1.7.0 (Git Commit: 249b76a)
Container image Copyright (c) 2024, NVIDIA CORPORATION & AFFILIATES. All rights reserved.
Copyright (c) 2014-2024 Facebook Inc.
Copyright (c) 2011-2014 Idiap Research Institute (Ronan Collobert)
Copyright (c) 2012-2014 Deepmind Technologies    (Koray Kavukcuoglu)
Copyright (c) 2011-2012 NEC Laboratories America (Koray Kavukcuoglu)
Copyright (c) 2011-2013 NYU                      (Clement Farabet)
Copyright (c) 2006-2010 NEC Laboratories America (Ronan Collobert, Leon Bottou, Iain Melvin, Jason Weston)
Copyright (c) 2006      Idiap Research Institute (Samy Bengio)
Copyright (c) 2001-2004 Idiap Research Institute (Ronan Collobert, Samy Bengio, Johnny Mariethoz)
Copyright (c) 2015      Google Inc.
Copyright (c) 2015      Yangqing Jia
Copyright (c) 2013-2016 The Caffe contributors
All rights reserved.

Various files include modifications (c) NVIDIA CORPORATION & AFFILIATES.  All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

NOTE: CUDA Forward Compatibility mode ENABLED.
  Using CUDA 12.6 driver version 560.35.03 with kernel driver version 550.144.03.
  See https://docs.nvidia.com/deploy/cuda-compatibility/ for details.

job is starting on gpua018.delta.ncsa.illinois.edu
Python 3.10.12
/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead
  warnings.warn(out)
/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Warp 1.3.3 initialized:
   CUDA Toolkit 12.5, Driver 12.6
   Devices:
     "cpu"      : "x86_64"
     "cuda:0"   : "NVIDIA A100-SXM4-40GB" (39 GiB, sm_80, mempool enabled)
   Kernel cache:
     /u/wzhong/.cache/warp/1.3.3
Creating data loaders...
Not finding in path 1
Creating data loaders...
Data loaders created: Train=2133, Val=355, Test=1067
Loading pretrained model ...
model training ...
/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
Module modulus.models.figconvnet.warp_neighbor_search 7da5518 load on device 'cuda:0' took 695.05 ms  (compiled)
Epoch 1/400, Loss: 0.00229951
validating
Current best validation errs by now: 0.20251774019758467
Epoch 2/400, Loss: 0.00224506
Epoch 3/400, Loss: 0.00217783
validating
Current best validation errs by now: 0.19504003436632558
Epoch 4/400, Loss: 0.00215241
Epoch 5/400, Loss: 0.00211156
validating
Current best validation errs by now: 0.1885413132502999
Epoch 6/400, Loss: 0.00207529
Epoch 7/400, Loss: 0.00206371
validating
Current best validation errs by now: 0.1841708927507132
Epoch 8/400, Loss: 0.00202558
Epoch 9/400, Loss: 0.00200939
validating
Current best validation errs by now: 0.1826485619158812
Epoch 10/400, Loss: 0.00198296
Epoch 11/400, Loss: 0.00196664
validating
Current best validation errs by now: 0.1826485619158812
Epoch 12/400, Loss: 0.00195370
slurmstepd: error: *** JOB 8981153 ON gpua018 CANCELLED AT 2025-04-09T19:27:10 DUE TO TIME LIMIT ***
